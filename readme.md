# Matrix GPT
## Introduction
In this project we Implement a GPT model following the research paper "Transformers are all you need" and Andrej Karpathy’s “Let’s Build GPT” series on Youtube. Our source text is the script of the movies "The Matrix" and "The Matrix Reloaded". We train the model on this text and then generate new text based on the trained model.
## Example Output
Without sufficient resources we will not get perfect results. But here is an example of the output generated by the model trained on a free google colab GPU.

" Thois, Thrinity strom-theacts and groub. I gassice want the
to gens to we sswaing, betare
hes of jomiugh as endlices.
(CONPOORPUED) 4/98 MACK
321 CONTINUED: 1455
The fick to come, surrken his
thert deas, jondy, there On'vere
ove snot itelly Buturn
to likiRON- whre hos ands dis.
A the ping, cand endilionn of out the
dastere.
NEO
No!
What goinst of dreabland in dres it
oon winds e144""

We can see that the model has a knowledge of the characters and the setting of the movie. It generates text that is similar to the script of the movie. The model is not perfect and the text generated is not coherent. But it is a good start and with more training and resources, we can get better results.

## Improvements
To improve this model without using extra resources (model depth), we should employ a tokenizer to use within the embedding space, rather than using chars only. Also exploring different model architectures, different hyperparameters and more data can all help to improve on my next GPT model.
